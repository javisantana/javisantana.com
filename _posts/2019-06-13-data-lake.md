---
layout: micro_post
published: true
name:  Data Lake parte I, Introducción
---


Yo no tengo ni idea de lo que es un data lake pero la [definición](https://en.wikipedia.org/wiki/Data_lake) se me parece a algo así: tira aquí todos
los datos y ya veremos.

Pinta bien, si algún día necesitas no sé qué dato para hacer machine learning, ahí está, lo coges y
lo usas.

Ahora, me pregunto: si es complicado mantener tus datos de producción, cómo demonios se mantiene
mínimamente organizado, y por tanto usable, toda la cantidad de datos que genera una empresa.

Los datos son como el cuerpo humano: las partes que no ejercitas son grasa y esta pasa factura a largo (y a corto) y necesitas ejercitarlo para que funcione bien

Pero imaginemos que el data lake es perfecto: 

- [II](/micro/2019-06-14-data-lake-fuentes.html). Es capaz de recoger datos de todas las fuentes.
- [III](/micro/2019-06-18-data-lake-catalogo.html). Tiene un catálogo de todos los datos con datos técnicos y de negocio
- [IV](/micro/2019-06-27-data-lake-cambios.html). Trazabilidad de cambios
- [V](micro/2019-07-25-data-lake-autorización.html). Acceso segmentado por usuario
- [VI](/micro/2019-08-28-data-lake-VI-trazabilidad.html). Auditoría de lo que ha pasado
- [VII](/micro/2019-09-28-data-lake-VII-datos-derivados.html). Posibilidad de tener datos derivados (aplicando todo los anteriores)
- [VIII](/micro/2019-09-28-data-lake-conclusiones.html). Conclusiones y opinión personal

Me cuesta ver como alguien que no está acostumbrado a los datos pueda abrir Tableu, engancharlo ahí
y sacar "insights". A un desarrollador, en teoría más cerca de los datos, le cuesta trabajar solo con los datos de producción...

Me pregunto, no tiene sentido que la exposición de los datos sea también lo que llamamos "producto"?

